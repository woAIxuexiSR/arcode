1. 数据集
   
   一系列 `*.json` 文件，每个文件中包含20轮实验数据，每轮数据：

   1. 以 `{"round" : , "target" : }` 开头，表示目标物体的世界坐标，深度 `z` 均为3
   
   2. 之后为每一帧的数据 `{"t": , ...}`
      
      `t` 表示与上一帧的时间差；
      
      `headOri, headDir, gazeOri, gazeDir` 分别表示头的位置、方向，视线的位置、方向；
      
      `gazeX, gazeY, targetX, targetY` 分别表示在以头为原点的局部坐标系下，视线和目标的方向，深度 `z` 均为1，（虽然这个数据可以通过前面的算出来，但是直接记下来比较方便）。

2. 目标
    
    预测注视点和目标物体的偏移，进行补偿
    
    令 `y = gazePos - target`
       
       `x1, x2,... = headPos, gazePos_{i-1}, ...?`
    
    求一个拟合的比较好的模型 `y = f(x1, x2, ...)`

    方法我比较倾向于 `sklearn` 里面的一些，比较好应用还好解释，不过直接深度学习也没啥问题